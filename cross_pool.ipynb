{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232c0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import inversefed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c7e57560",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(41)\n",
    "dm = torch.as_tensor(inversefed.consts.cifar10_mean, device='cuda')[:, None, None]\n",
    "ds = torch.as_tensor(inversefed.consts.cifar10_std, device='cuda')[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6e571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf05d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv2d(3, 24, 5, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(24, 48, 5, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        )\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC = nn.Sequential(\n",
    "                nn.Linear(2352, 120),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(120, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        y = self.Flatten(y)\n",
    "        y = self.FC(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c861e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alex_nopool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Alex_nopool, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(24, 48, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3 ,stride=1, padding=1)\n",
    "        )\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.Flatten(x)\n",
    "        return self.FC(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15111506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Alex, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=1),\n",
    "            nn.Conv2d(24, 48, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(1728, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.Flatten(x)\n",
    "        return self.FC(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72f6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889eb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10('/mnt/ssd4/weiyang/Dataset/cifar-10-python/', train=True, transform=torchvision.transforms.ToTensor(), download=False)\n",
    "train_loader = DataLoader(trainset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79f011ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('images/LeNet_whole/orig_%d.png'%idx, train_loader.dataset[80][0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef57849",
   "metadata": {},
   "source": [
    "### Generate Original Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1eba6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 80\n",
    "orig, label = train_loader.dataset[idx]\n",
    "orig, label = orig[None, :].to('cuda'), torch.tensor([label]).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "orig_y = model(orig)\n",
    "orig_loss = criterion(orig_y, label)\n",
    "input_gradient = torch.autograd.grad(orig_loss, model.parameters())\n",
    "input_gradient = [grad.detach() for grad in input_gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(signed=True,\n",
    "              boxed=True,\n",
    "              cost_fn='sim',\n",
    "              indices='def',\n",
    "              weights='equal',\n",
    "              lr=0.1,\n",
    "              optim='adam',\n",
    "              restarts=1,\n",
    "              max_iterations=24000,\n",
    "              total_variation=1e-2,\n",
    "              init='randn',\n",
    "              filter='none',\n",
    "              lr_decay=True,\n",
    "              scoring_choice='loss')\n",
    "\n",
    "num_images = 1\n",
    "rec_machine = inversefed.GradientReconstructor(model, (dm, ds), config, num_images=num_images)\n",
    "output = rec_machine.reconstruct(input_gradient, label, img_shape=(3, 32, 32))\n",
    "#output, stats = rec_machine.reconstruct(input_gradient, label, img_shape=(3, 32, 32))\n",
    "\n",
    "#plt.imsave('images/orig%d.png'%idx, orig.cpu().numpy().transpose([0,2,3,1]).squeeze(axis=0))\n",
    "plt.imsave('images/LeNet_whole/wide_%d.png'%idx, output[0].cpu().numpy().transpose([0,2,3,1]).squeeze(axis=0).clip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35fd289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f92857202e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0].cpu().numpy().transpose(0,2,3,1).squeeze(axis=0).clip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca660062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_fc(input_grad, model, label):\n",
    "    x_trial = torch.randn((1,2352)).to('cuda')\n",
    "    optimizer = torch.optim.LBFGS([x_trial])\n",
    "    for i in range(600):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            trial_pred = model.FC(x_trial)\n",
    "            loss = loss_fn(trial_pred, label)\n",
    "            trial_grad = torch.autograd.grad(loss, model.parameters(), create_graph=True, allow_unused=True)\n",
    "            grad_loss = 0\n",
    "            for i in range(4, len(trial_grad)):\n",
    "                grad_loss += (input_grad[i]-trial_grad[i]).pow(2).sum()\n",
    "            grad_loss.backward()\n",
    "            return grad_loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "    return x_trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cac7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_x(model, bef_pool):\n",
    "    x_trial = torch.randn((1,3,32,32)).to('cuda')\n",
    "    optimizer = torch.optim.LBFGS([x_trial])\n",
    "    for i in range(600):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            pred_bef_pool = model.conv[3](model.conv[2](model.conv[1](model.conv[0](x_trial))))\n",
    "            loss = (pred_bef_pool-bef_pool).pow(2).sum()\n",
    "            loss.backward(retain_graph = True)\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "    return x_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1ee153cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bef_fc = rec_fc(input_gradient, model, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd15eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_pool = model.conv[3](model.conv[2](model.conv[1](model.conv[0](train_loader.dataset[80][0][None, :].to('cuda')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4040729a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1711737/2410232452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrec_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbef_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1711737/1285931764.py\u001b[0m in \u001b[0;36mrec_x\u001b[0;34m(model, bef_pool)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1711737/1285931764.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpred_bef_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_bef_pool\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbef_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd4/weiyang/anaconda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "rec_x(model, bef_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c6a3823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2332.5212, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.Flatten(model.conv(orig))-bef_fc).cpu().pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc629af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_pool(aft_pool):\n",
    "    aft_pool = aft_pool.view(1,32,7,7)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
